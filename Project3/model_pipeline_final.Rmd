---
title: "model_results"
output: html_document
date: "2023-11-25"
---

```{r}
library(dplyr)
library(tidymodels)
library(doParallel)
library(vip)
library(randomForest)
library(themis)
library(bonsai)
library(lightgbm)
library(caret)
```

# Dataset to use for modelling
## Getting a smaller sample
```{r}
file1 <- read.csv("~/github/Team-69/Data/Loan_Default1.csv")
file2 <- read.csv("~/github/Team-69/Data/Loan_Default1.csv")

loan_df <- bind_rows(file1, file2)

set.seed(2023)
loan_sample <- loan_df[sample(1:nrow(loan_df), 75000),]
```
First we are going to use a smaller dataset to check the hyperparameter space to see generally which hyperparameters we should use. We do this because hyperparameter tuning takes a very long time to run so we want to explore a bit before we run the first models.

## Sample train/test split

```{r}
set.seed(2023)
# Initial loan split

sample_split <- loan_sample %>%
  ## Removing several category variables because they only contain one value
  select(-ID, -year, -construction_type, -rate_of_interest, -Interest_rate_spread, -Upfront_charges, -term,
         -construction_type, -Secured_by, -Security_Type) %>% 
  mutate(Status = factor(Status)) %>% 
  initial_split()
        
sample_train <- training(sample_split)
sample_test <- testing(sample_split)

```

## Recipe for modelling pipeline

```{r}
base_rec <- 
  recipe(Status ~ ., data = sample_train) %>%
  # Use bagged models to fill in missing data
  step_impute_bag(income, dtir1, LTV, property_value,submission_of_application, impute_with=imp_vars(all_predictors())) %>%
  step_dummy('loan_limit', 'Gender', 'approv_in_adv', 'loan_type', 'loan_purpose', 'Credit_Worthiness', 'open_credit', 'business_or_commercial', 'Neg_ammortization', 'interest_only', 'lump_sum_payment', 'occupancy_type', 'total_units', 'credit_type', 'co.applicant_credit_type', 'age', 'submission_of_application', 'Region')
```
In this step, we are setting up the basic recipe to feed into our model

This includes imputing all missing values using a bagged model method and transforming the categorical variables into dummy variables

## Random forest exploration
```{r}

rf_spec <-
  rand_forest(
    mtry = tune(),
    trees = tune(),
    min_n = tune()
  ) %>%
  set_mode("classification") %>%
  set_engine("ranger")


rf_grid <- grid_latin_hypercube(
  trees(range=c(50,1000)),
  min_n(),
  finalize(mtry(),select(sample_train,-Status)),
  size = 30
)


rf_wf <- workflow() %>%
  add_recipe(base_rec) %>%
  add_model(rf_spec)

```

Here we set up the random forest specification which will run the model and also set up a hyperparameter grid to tune the parameters
### DO NOT RUN BLOCK BELOW - WILL TAKE AWHILE ###

```{r}
# set.seed(1234)
# sample_fold <- vfold_cv(sample_train, v=10, strata = Status)
# 
# 
# doParallel::registerDoParallel()
# 
# set.seed(234)
# rf_res <- tune_grid(
#   rf_wf,
#   resamples = sample_fold,
#   grid = rf_grid,
#   control = control_grid(save_pred = TRUE)
# )

```

```{r}
autoplot(rf_res)
```

From looking at the graphs, we can observe that mtry is the only parameter with some relationship with accuracy and roc_auc. Lower values of mtry seem to perform much worse and the performance of the models get better as mtry becomes higher.

We also see a slight negative linear trend between minimal node size and roc_auc/accurcacy. We'll limit to ower values of minimal node size in the final model tuning.

We'll set the range of for mtry to (10,20) range and minimal node size to (0,20) when we tune the final model.

```{r}
lgb_spec <- boost_tree(
  trees = 500,
  tree_depth = tune(), min_n = tune(),
  loss_reduction = tune(),                     
  sample_size = tune(), mtry = tune(),         
  learn_rate = tune()                       
) %>%
  set_engine("lightgbm") %>%
  set_mode("classification")

lgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(),select(sample_train,-Status)),
  learn_rate(range = c(-3, 0)),
  size = 50
)


lgb_wf <- workflow() %>%
  add_recipe(base_rec) %>%
  add_model(lgb_spec)
```

Here we set the light GBM specification. We are using light GBM because the performance is comparable to XGBoost while being much less computationally expensive.

We set the trees at 500 since the # of trees don't seem to affect the performance of the models much but we set a grid to look at all the other hyperparameters

### DO NOT RUN BLOCK BELOW - WILL TAKE AWHILE ###
```{r}
# doParallel::registerDoParallel()
# 
# set.seed(234)
# lgb_res <- tune_grid(
#   lgb_wf,
#   resamples = sample_fold,
#   grid = lgb_grid,
#   control = control_grid(save_pred = TRUE)
# )

```
```{r}
autoplot(lgb_res)
```

After the models run, we can see again that most parameters don't have much of a relationship with the performance of the models.

Though there are two variables that show a bit of a relationship with accuracy and roc_auc.

Learning rate seems to have a quadratic relationship with the performance of the models. The lower and higher values of learning rate seem to perform worse that the values in the middle showing a quadratic shape.

We'll set the learning rate range from (-2, -0.5) for the final model tuning.



# Final Model

```{r}
set.seed(2023)
loan_split <- loan_df %>%
  ## Removing several category variables because they only contain one value
  select(-ID, -year, -construction_type, -rate_of_interest, -Interest_rate_spread, -Upfront_charges, -term,
         -construction_type, -Secured_by, -Security_Type) %>% 
  mutate(Status = factor(Status)) %>% 
  initial_split()
        
loan_train <- training(loan_split)
loan_test <- testing(loan_split)

```


```{r}
rf2_spec <-
  rand_forest(
    mtry = tune(),
    trees = 500,
    min_n = tune()
  ) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "impurity")

lgbm2_spec <- boost_tree(
  trees = 500,
  tree_depth = tune(), min_n = tune(),
  loss_reduction = tune(),                     
  sample_size = tune(), mtry = tune(),         
  learn_rate = tune()) %>%
  set_mode("classification") %>% 
  set_engine("lightgbm", importance = "impurity") 

log_spec <-
  logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
```

```{r}
rf2_param <- parameters(min_n(), mtry()) %>% 
  update(min_n = min_n(c(0, 20)),
         mtry = mtry(c(10, 20)))

lgbm2_param <-
  parameters(tree_depth(), min_n(), sample_size(), mtry(), loss_reduction(), learn_rate()) %>% 
   update(
          learn_rate = learn_rate(c(-2,-.5)),
          mtry = finalize(mtry(),select(loan_train,-Status)),
          sample_size = sample_prop(c(0.75, 1)))


smote_rec <- base_rec %>%
  step_smote(Status)

loan_set <-
  workflow_set(
    preproc=list(base_recipe=base_rec, smote_recipe=smote_rec,base_recipe=base_rec,base_recipe=base_rec),
    models=list(Logistic=log_spec, LogisticSmote=log_spec, RandomForest=rf2_spec, LightGBM = lgbm2_spec),
    # models=list(Logistic=log_spec, LogisticSmote=log_spec),
    cross = FALSE
  )
```


### DO NOT RUN BLOCK BELOW - WILL TAKE AWHILE ###

```{r}
# set.seed(1234)
# loan_folds <- vfold_cv(loan_train, v=10, strata = Status)
# 
# doParallel::registerDoParallel()
# 
# loan_rs <-loan_set %>%
#   option_add(param_info = rf2_param, id = "base_recipe_RandomForest") %>%
#   option_add(param_info = lgbm2_param, id = "base_recipe_LightGBM") %>%
#   workflow_map(
#     fn = "tune_grid",
#     resamples = loan_folds,
#     grid = 20,
#     control = control_grid(save_workflow = TRUE),
#     seed=2023
#   )
```


## Imbalanced class resampling
```{r}
model_results <- collect_metrics(loan_rs)

model_results %>% filter(wflow_id %in% c('base_recipe_Logistic', 'smote_recipe_LogisticSmote'))
```

To test if imbalanced class resampling helps our model - we applied the SMOTE technique to sample more of the default cases.

We ran a logistic model with and without using smote and we find that the mean fold accuracy is actual worse with the smote resampling technique.

Though the roc_auc is slightly higher using SMOTE, the accuracy difference is much higher. Therefore we will not use the resampling technique in the final model



```{r}
autoplot(loan_rs)
```

This graph shows the different Random Forest and Light GBM models with different hyper parameters. We can see that the top performing models (according to roc_auc) are all Light GBM models. We will use the model which has both the highest accuracy and roc_auc


## Extracting best model and predicting on the test set
```{r}
best_model_fit <- fit_best(loan_rs)

final_predictions <- predict(best_model_fit, loan_test %>% select(-Status))


lgb_fit <- extract_workflow_set_result(loan_rs, 'base_recipe_LightGBM') %>% 
  fit_best()

lgb_predictions <- predict(lgb_fit, loan_test %>% select(-Status))

logistic_fit <- extract_workflow_set_result(loan_rs, 'base_recipe_Logistic') %>% 
  fit_best()

logistic_predictions <- predict(logistic_fit, loan_test %>% select(-Status))
```


## Confusion matrix on the predictions
```{r}
confusionMatrix(final_predictions %>% pull(), loan_test %>% pull(Status), positive = '1')
confusionMatrix(lgb_predictions %>% pull(), loan_test %>% pull(Status), positive = '1')
```

Here we are comparing the best models for both Light GBM and Random Forest. We can see that the random forest model actually performs significantly better than the Light GBM model which is surprising since Light GBM tends to perform better overall.

The Random Forest model has a ~5% increase in accuracy compared to the Light GBM model but the more important difference is the ~19% increase in the sensitivity rate. This means there is a 19% improvement in identifying loan defaults, which is a huge improvement.




```{r}
confusionMatrix(logistic_predictions %>% pull(), loan_test %>% pull(Status), positive = '1')
```

We can also see that both models perform much better than a logistic regression


## Variable Importance
```{r}
best_model_fit %>% vip(num_features = 20)
```
This shows the variable importance plot for the random forest model. It seems that the most important variables for prediction were credit_type, LTV, income, dtir1, property_value, Credit Score, and loan amount
